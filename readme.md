# German Med-BERT Training and Prediction

This repository provides a pipeline for training and evaluating a German Med-BERT model for medical text classification. The script supports both training and prediction modes.

## ğŸš€ Features
	â€¢	Preprocesses medical text data for training and inference.
	â€¢	Trains a multi-label classification model using GerMedBERT.
	â€¢	Evaluates model performance and generates plots (confusion matrices, training progress).
	â€¢	Supports inference on new medical text data.

## Installation
### Clone Repository
```
git clone https://github.com/your-repo-name.git
cd your-repo-name
```
### Install Dependencies
```
pip install -r requirements.txt
```

## ğŸ— Usage

The script supports two modes:
	â€¢	Training (train)
	â€¢	Prediction (predict)

ğŸ”¹ 1ï¸âƒ£ Training Mode

Train the German Med-BERT model using labeled medical text data.
```
python main.py --mode train --data path/to/data.csv --rp results_dir --t text_column_name
```

|Argument|Description|
|--mode|Takes train or predict. Runs the training or prediction process.|
|--data|Path to the dataset or directory for inference.|
|--rp|Directory where results will be saved.|
|--t|Name of the text column(s) (Must be the same for all input datasets).|

## ğŸ“Š Output
	â€¢	Trained Model (results_dir/results/)
	â€¢	Evaluation Metrics (F1-score, accuracy, loss)
	â€¢	Plots:
	â€¢	Confusion Matrix (training_confusion_matrix.png)
	â€¢	Training Progress (training_loss.png, training_f1.png, training_accuracy.png)

## ğŸ›  Project Structure

```
/project-root
â”‚â”€â”€ main.py                   # Main script for training and inference
â”‚â”€â”€ preprocessing.py           # Data cleaning and preprocessing
â”‚â”€â”€ model_prep.py              # Model preparation and training functions
â”‚â”€â”€ load_data.py               # Data loading utilities
â”‚â”€â”€ models.py                  # Custom dataset classes
â”‚â”€â”€ plot_results.py            # Plot generation (confusion matrix, training metrics)
â”‚â”€â”€ requirements.txt           # Required dependencies
â”‚â”€â”€ results/                   # Directory for model outputs and plots
```

## ğŸ“¢ Acknowledgment

This project leverages GerMedBERT, a pretrained transformer model for medical NLP in German. Model available on Hugging Face.

For more details, visit GerMedBERT on Hugging Face.
